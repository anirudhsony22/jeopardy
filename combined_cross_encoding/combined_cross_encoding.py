# -*- coding: utf-8 -*-
"""combined_cross_encoding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o_a42Q4TNL_EBKeXdpSbTVhiRttrmlih
"""

import os
import pickle
import json
import re
from tqdm import tqdm
from sentence_transformers import CrossEncoder
from collections import defaultdict

# !cp /content/nltk_chunking.jsonl /content/drive/MyDrive/jeopardy_project/results/nltk_chunking.jsonl

base_dir = '/content/drive/MyDrive/jeopardy_project/results/'
bge_path = f'{base_dir}bge_eval_hits.pkl'
multiqa_path = f'{base_dir}multiqa_eval_hits.pkl'
doc_id_to_text_path = f'{base_dir}doc_titles.pkl'
output_path = f'{base_dir}final_rerank_recall_results.pkl'

chunk_file = f'{base_dir}nltk_chunking.jsonl'

cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

with open(bge_path, 'rb') as f:
    bge_results = pickle.load(f)

with open(multiqa_path, 'rb') as f:
    multiqa_results = pickle.load(f)

# Normalize MultiQA format
multiqa_dict = {
    entry['question']: set(entry['retrieved_docs'][:50])
    for entry in multiqa_results
}

# === Load all chunks by doc_id
doc_to_chunks = defaultdict(list)
with open(chunk_file, 'r') as f:
    for line in f:
        entry = json.loads(line)
        doc_id = entry['doc_id']
        chunk = entry['proposition_text'].strip()
        if chunk:
            doc_to_chunks[doc_id].append(chunk)

# === Fuzzy matcher
def relaxed_answer_match(answer, text, threshold=0.8):
    answer_tokens = re.findall(r'\w+', answer.lower())
    text_tokens = set(re.findall(r'\w+', text.lower()))
    if not answer_tokens:
        return False
    match_count = sum(1 for token in answer_tokens if token in text_tokens)
    return (match_count / len(answer_tokens)) >= threshold

# === Evaluate
k_values = [1, 10, 25, 50, 100]
hits_at_k = defaultdict(int)
total = len(bge_results)
all_results = []

for i, (question, answer, bge_docs, _) in enumerate(tqdm(bge_results, desc="Hybrid rerank eval")):
    multiqa_docs = multiqa_dict.get(question, set())
    selected_docs = list(dict.fromkeys(bge_docs[:25] + list(multiqa_docs)))  # merge + dedup

    rerank_pairs = []
    doc_chunks = {}
    for doc_id in selected_docs:
        chunks = doc_to_chunks.get(doc_id, [])
        doc_chunks[doc_id] = chunks
        for chunk in chunks:
            rerank_pairs.append((question, chunk))

    if not rerank_pairs:
        all_results.append((question, answer, [], False))
        continue

    scores = cross_encoder.predict(rerank_pairs)

    # Map back to doc_id via chunk order
    idx = 0
    doc_scores = {}
    for doc_id in selected_docs:
        chunks = doc_chunks.get(doc_id, [])
        chunk_scores = scores[idx:idx + len(chunks)]
        idx += len(chunks)
        if len(chunk_scores)>0:
            doc_scores[doc_id] = max(chunk_scores)

    # Sort docs by max chunk score
    sorted_docs = [doc for doc, _ in sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)]

    # Check fuzzy match in any chunk of top-k docs
    found = False
    for k in k_values:
        for doc_id in sorted_docs[:k]:
            for chunk in doc_to_chunks.get(doc_id, []):
                if relaxed_answer_match(answer, chunk):
                    hits_at_k[k] += 1
                    found = True
                    break
            if found:
                break

    all_results.append((question, answer, sorted_docs[:10], found))

# === Print results
print("\n\u2728 Hybrid Ensemble Recall Results:")
for k in k_values:
    recall = hits_at_k[k] / total
    print(f"Recall@{k:3}: {recall:.2%} ({hits_at_k[k]}/{total})")

# === Save detailed results
with open(output_path, 'wb') as f:
    pickle.dump(all_results, f)
print(f"\nâœ… Saved results to: {output_path}")



