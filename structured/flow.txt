parse -> chunk -> embed chunks -> combine chunks -> faiss

parse_documents.py - just run once to create doc_contents.pkl and doc_titles.pkl
chunk_documents.py - chunk the documents and save the chunks in chunks_{no.of.chunks} folder in database
embed_chunks.py - run for different chunk sizes (SBERT supports upto 512 tokens in a chunk)
combine_chunks.py - combines the data from embedded chunks (These chunks are different from previous)
faiss_vector_build.py  - builds the faiss vector for given embedded chunks

query_test.py


BGE Pre-filtering timings/recall (100 queries):
10000 documents/query: 82s, Recall: 82%
1000 documents/query: 47s, Recall: 80%


